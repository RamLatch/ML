{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "32f722e6b24c832b7917e7e3f41e9eea",
     "grade": false,
     "grade_id": "cell-8a7cd222d4950599",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise Sheet No. 3\n",
    "\n",
    "---\n",
    "\n",
    "> Machine Learning for Natural Sciences, Summer 2022, Jun.-Prof. Pascal Friederich, pascal.friederich@kit.edu\n",
    "> \n",
    "> Deadline: 08.05.2023, 8 am\n",
    ">\n",
    ">Container version 1.0.0\n",
    "> \n",
    "> Tutor: luca.torresi@kit.edu  \n",
    "> **Please ask questions in the forum and only contact the Tutor when there are issues with the grading**\n",
    "---\n",
    "\n",
    "**Topic**: This exercise sheet will focus on linear algebra, knn classifier, precision, recall, ROC curves and feature reduction. You will continue to use ``numpy`` methods."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please add here your group members' names and student IDs. \n",
    "\n",
    "Names: Robin Maurer, \n",
    "\n",
    "IDs: 2462304, \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f8ffb30bf172b0c558a7d62470462174",
     "grade": false,
     "grade_id": "cell-c26ffc5de714a368",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 3.1 Distance function computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ccbb0e442ec0d33e6b416949e7ea3a7a",
     "grade": false,
     "grade_id": "cell-4bf94758d89ed7fa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "For many feature descriptors and also for a specific implementation of the nearest neighbor classifier, the Euclidean mutual distance between a set of points must be computed. This serves as a measure on how two points are distinct or how far apart they are in Euclidean space. We will make use of this very often in the future. Therefore this exercise focus on an efficient implementation using numpy. You should gain a better unstanding of `numpy` methods.\n",
    "\n",
    "**3.1.1** Implement a function ``dist_loop(A,B)`` to computes the Euclidean distance between all instances between two sets of points $A \\subset \\mathbb{R}^{D}$ and $B \\subset \\mathbb{R}^{D}$. The input should be two matrices of shape $N \\times D$ and $M \\times D$. Do this by using explicit python loops to find the distance $d_{ij} = || a_{i} - b_{j} ||$ between two points $a_{i} \\in A$ and $b_{i} \\in B$. The output should be a $N \\times M$ distance matrix. For the calculation of the Euclidean distance you might want to use ``numpy.square()``, ``numpy.sum()`` and ``numpy.sqrt()``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "90e6ddbc23e3e3b9b41fbb33d6f9be05",
     "grade": false,
     "grade_id": "cell-c33edbe7e3ce1318",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import random\n",
    "import sys\n",
    "n = 500\n",
    "m = 1000\n",
    "d = 3\n",
    "A_data = np.reshape(random.rand(n*d),(n,d))\n",
    "B_data = np.reshape(random.rand(m*d),(m,d))\n",
    "print(\"A shape:\", A_data.shape, \"B shape:\", B_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8501f3bf68a844bf562dc6c0f94bb1d3",
     "grade": false,
     "grade_id": "dist_loop",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def dist_loop(A,B):\n",
    "    if A.shape[-1] != B.shape[-1]:\n",
    "        raise ValueError(\"Error A and B must have same last dimension but got\", A.shape[-1], B.shape[-1])\n",
    "    n = A.shape[0]\n",
    "    m = B.shape[0]\n",
    "    distances = np.zeros((n, m))\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            diff = A[i] - B[j]\n",
    "            distances[i, j] = np.sqrt(np.sum(np.square(diff)))\n",
    "    \n",
    "    return distances\n",
    "    #raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1ebc80096c88ae8a5d08209629141cc1",
     "grade": false,
     "grade_id": "cell-fa9a5e0893f92ee1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**3.1.2** Since loops are rather slow in python, and more efficient code is required for numeric operations, write another function ``dist_vec(A,B)`` to compute the distance relying\n",
    "on vectorization with ``numpy`` methods. Consult https://www.safaribooksonline.com/library/view/python-for-data/9781449323592/ch04.html and https://softwareengineering.stackexchange.com/questions/254475/how-do-i-move-away-from-the-for-loop-school-of-thought for information on how to do this. \n",
    "\n",
    "Tip: There is more than one way to do it. For the most straightforward answer, you need to add an additional dimension to `np.arrays` via, for example, `expand_dims`. If two `np.arrays` do not have matching shape they are then automatically broadcasted by repeating their respective element along the axis in question. Beside broadcasting, also the [indexing rules](https://numpy.org/doc/stable/reference/arrays.indexing.html) (required for 3.2, 3.3) of `numpy` help with vectorization to avoid python loops. You must not use ``scipy`` or its methods for this task!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c528a8f299889fc60698e8e2ca273aad",
     "grade": false,
     "grade_id": "dist_vec",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def dist_vec(A,B):\n",
    "    if A.shape[-1] != B.shape[-1]:\n",
    "        raise ValueError(\"Error A and B must have same last dimension but got\", A.shape[-1], B.shape[-1])\n",
    "    \n",
    "    \n",
    "    \n",
    "    A_squared = np.sum(np.square(A), axis=1)\n",
    "    B_squared = np.sum(np.square(B), axis=1)\n",
    "    AB = np.dot(A, B.T)\n",
    "    \n",
    "    distances = np.sqrt(np.expand_dims(A_squared, axis=1) + np.expand_dims(B_squared, axis=0) - 2 * AB)\n",
    "    \n",
    "    return distances\n",
    "    #raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b7df20b8c939c99028a2d58adbf4d0f6",
     "grade": false,
     "grade_id": "cell-fc0ec9c589763c8a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Check that the two function return the same result. And check the output shape of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d4b043d946187d5d4b08030dc999dd25",
     "grade": false,
     "grade_id": "difference_dist",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "result_loop = dist_loop(A_data,B_data)\n",
    "result_vec = dist_vec(A_data,B_data)\n",
    "result_vec_shape = np.shape(result_vec) # Check shape of result_loop\n",
    "result_loop_shape = np.shape(result_loop) # Check shape of result_vec\n",
    "\n",
    "assert np.allclose(result_loop, result_vec)\n",
    "assert result_vec_shape == result_loop_shape\n",
    "\n",
    "print(\"Shape of result_loop:\", result_loop_shape)\n",
    "print(\"Shape of result_vec:\", result_vec_shape)\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e12995c578ef850b181a8480d7efb5e4",
     "grade": false,
     "grade_id": "cell-b4c698e9d03d3613",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now compare the run times of the two implementations using jupyter's ``%timeit`` command or pythons ``time``. How much faster is the vectorized version?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a4b2b3eb3f759651f178003bf2c921c2",
     "grade": false,
     "grade_id": "cell-86d6de253ac2af1b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# measure time for loop\n",
    "%timeit result_loop = dist_loop(A_data,B_data)\n",
    "# measure time for vectorized\n",
    "%timeit result_vec = dist_vec(A_data,B_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity test because I dont know how to read timeit. Frage: warum haben die eine unterschiedliche Anzahl an loops?\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "dist_loop(A_data, B_data)\n",
    "dist_loop(A_data, B_data)\n",
    "dist_loop(A_data, B_data)\n",
    "dist_loop(A_data, B_data)\n",
    "dist_loop(A_data, B_data)\n",
    "dist_loop(A_data, B_data)\n",
    "dist_loop(A_data, B_data)\n",
    "end_time = time.time()\n",
    "print(\"Runtime of dist_loop():\", (end_time - start_time)/7, \"seconds\")\n",
    "\n",
    "start_time = time.time()\n",
    "dist_vec(A_data, B_data)\n",
    "dist_vec(A_data, B_data)\n",
    "dist_vec(A_data, B_data)\n",
    "dist_vec(A_data, B_data)\n",
    "dist_vec(A_data, B_data)\n",
    "dist_vec(A_data, B_data)\n",
    "dist_vec(A_data, B_data)\n",
    "end_time = time.time()\n",
    "print(\"Runtime of dist_vec():\", (end_time - start_time)/7, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b24b19b8a3cbe955f59b06db7827d968",
     "grade": false,
     "grade_id": "speed_up",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "speed_up_factor = 420 # A rough estimation is okay.\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "64d6dfd3de6acc0e4594434ae7059cdd",
     "grade": false,
     "grade_id": "cell-a20dc8356bb8b477",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Note: It is absolutely critical that you understand vectorization, and with this the indexing and broadcasting methods of numpy. Not only do we need fast performance, but also all deep learning frameworks are based on array or tensor operations just like you used with ``numpy``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "199a7da406fe7b3c9659a4b52f53dc2e",
     "grade": true,
     "grade_id": "test_funs_1",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test for grading\n",
    "assert callable(dist_loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "05643463f89fd50e041bf163fdca4b47",
     "grade": true,
     "grade_id": "test_funs_2",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert callable(dist_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "839e15828e766b4554ff180df1e77b79",
     "grade": true,
     "grade_id": "test_loop_diff",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test for grading\n",
    "assert result_loop is not None\n",
    "assert result_vec is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5c6c6b013eac1bb0f4bca02179c6d58e",
     "grade": true,
     "grade_id": "test_shape_dist",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert result_vec_shape is not None\n",
    "assert result_loop_shape is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4a6e71ce926e10b1a242d37373052a61",
     "grade": true,
     "grade_id": "speed_up_test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test for grading\n",
    "assert speed_up_factor > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fc2738648d5a0815497e45f7ae8687f8",
     "grade": false,
     "grade_id": "cell-cae27f50792e197e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 3.2 Precision-Recall Curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6aa67ae4927b4796aa4ec686bd349a7b",
     "grade": false,
     "grade_id": "cell-9f173d428aa9d6b2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In this exercise, we use sklearn's digits dataset for an image classification experiment. Each image has 64 grey scale pixels. <br> \n",
    "We will use a small subset of the dataset as training set for a k-nearest neighbor classifier to classify the rest of the images depending on the digit they represent. To apply knn we need a measure of similarity: we will use the previously implemented distance function to compute the euclidian distance between couples of image vectors. <br> \n",
    "Let's start loading the dataset, splitting it in a train and a test set and having a lookat some images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "13cae695b390766e072d1eba05177fcb",
     "grade": false,
     "grade_id": "cell-4694919154d6a077",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_digits\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# read and prepare the digits data\n",
    "digits = load_digits()\n",
    "data = digits[\"data\"]\n",
    "images = digits[\"images\"]\n",
    "target = digits[\"target\"]\n",
    "\n",
    "# split data in train and test set\n",
    "X_labeled, X_unknown, y_labeled, y_unknown = train_test_split(data, target, test_size=0.98, random_state=42)\n",
    "print(f'Train set shape: {X_labeled.shape}; test set shape: {X_unknown.shape}\\n\\n')\n",
    "\n",
    "# Show digits\n",
    "print(f'Example of images from classes: {target[:3]}')\n",
    "fig = plt.figure(figsize = (10,3))\n",
    "plt.gray()\n",
    "plt.subplot(1,3,1); plt.axis('off')\n",
    "plt.imshow(images[0])\n",
    "plt.subplot(1,3,2); plt.axis('off')\n",
    "plt.imshow(images[1])\n",
    "plt.subplot(1,3,3); plt.axis('off')\n",
    "plt.imshow(images[2])\n",
    "fig.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e4bbd072f199adad50c4b3c0d388489a",
     "grade": false,
     "grade_id": "cell-3a005da3224b0a6c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Knn is a simple non-parametric model. For each datapoint in the test set we want to build a list, sorted by a similarity measure, of all the datapoints in the train set. Then the output of the classifier is determined by the \"votes\" of the k closest train datapoints. For example we can simply select as predicted class the most common class among the closest neighbors. Or, in a binary classification setting, define the probability of an object to belong to a given class as the normalized number of positive votes and then predict positively if the probability is over a pre-set threshold.\n",
    "\n",
    "Let's implement a simple Knn classifier that can work both for a multiclass setting and as binary classifier when we specify the digit of interest. We will need the binary classifier to discuss some common performance metrics later on.\n",
    "\n",
    "We will use the Euclidean distance between pixel values as similarity measure:\n",
    "\n",
    "$d(X_i,X_{i'} ) = || X_i - X_{i'}||_2$\n",
    "\n",
    "To efficiently compute these distances, you should use vectorization from exercise 3.1. Let $D$\n",
    "be the full dissimilarity matrix, i.e. $D_{i i'} = d(X_i,X_{i'})$. An ``np.argsort()`` of row $D_i$ now gives the similarity ordering of all images $X_{i'}$ in the train set relative to image $X_i$.\n",
    "\n",
    "\n",
    "Note: If you didn't manage to solve 3.1 you can now use `scipy.spatial.distance.cdist`. But you do not get points for this solution in 3.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "71df2daf956c493fe7c2b9c2af84581f",
     "grade": false,
     "grade_id": "knn_classifier",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "class Knn_Classifier:\n",
    "    def __init__(self, X_unknown, X_labeled, y_labeled):\n",
    "        D = dist_vec(X_unknown, X_labeled)                # compute distances from each X_unknown to each X_labeled\n",
    "        nn = np.argsort(D)               # order neighbors from closest to furthest\n",
    "        self.nn_targets = y_labeled[nn]  # store labels (our 'votes') of the ordered neighbors (given by y_labeled)\n",
    "\n",
    "#raise NotImplementedError()\n",
    "\n",
    "    def set_k(self, k):\n",
    "        self.knn_targets = self.nn_targets[:,:k]      # restrict list of labels to k closest neighbors\n",
    "\n",
    "#raise NotImplementedError()\n",
    "        \n",
    "    def __call__(self, label: int = None, threshold: float = .5):\n",
    "        counters = [Counter(self.knn_targets[i]) for i in range(self.knn_targets.shape[0])]\n",
    "        if label is None:\n",
    "            # multiclass classifier, for each data point it outputs the most \"voted\" class by the neighbors\n",
    "            preds = np.asarray([c.most_common(1)[0][0] for c in counters])\n",
    "            return preds\n",
    "        else:\n",
    "            # binary classifier for digit 'label'\n",
    "            # computes the probability a given data point belongs to a class or to any of the others\n",
    "            # as the number of votes for that class normalized over the total number of votes\n",
    "            probs = np.asarray([c.get(label, 0)/sum(c.values()) for c in counters])\n",
    "            # predicts as belonging to the class 'label' if the computed probability exceeds the threshold\n",
    "            preds = (probs>=threshold).astype(int)\n",
    "            return preds, probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0f3a4d1b7c51d8dca92ecd981227a216",
     "grade": false,
     "grade_id": "cell-0c1571f58a01fa3b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's run a multiclass knn classification setting the number of neighbors k to 5. \n",
    "\n",
    "To have an overview of the goodness of the classification we will print a confusion matrix. A confusion matrix is defined as the matrix $C$ such that $C_{ij}$ is equal to the number of observations known to be in group $i$ and predicted to be in group $j$. It can be easily computed using the function \"confusion_matrix\" from sklearn.metrics and we'll plot it using seaborn heatmaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7d3f3d749569eb954ca238137676633e",
     "grade": false,
     "grade_id": "cell-1b7c0cef909cd1ca",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "knn = Knn_Classifier(X_unknown, X_labeled, y_labeled)\n",
    "knn.set_k(5)\n",
    "preds = knn()\n",
    "print(np.shape(preds),np.shape(y_unknown))\n",
    "cf_matrix = confusion_matrix(y_unknown, preds)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "ax = sns.heatmap(cf_matrix, annot=True, fmt='', cmap='Blues')\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('Ground truth labels')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d9764b0435e8adeaea0f4ee8d1dfa624",
     "grade": false,
     "grade_id": "cell-e875203b21c8141c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Each row of the confusion matrix represents the instances in an actual class while each column represents the instances in a predicted class. Once produced, we can use it directly to compute some performance measures. We will have a look at two evaluation metrics used to assess the performance of a machine learning model in a binary classification problem: precision and recall. \n",
    "\n",
    "In a binary setting, so considering in our example one class against all other classes, we can define:\n",
    "<ol>\n",
    "<li><p>true positives (TP): number of objects belonging to the class that were $\\textbf{correctly}$ predicted as belonging to it; </p>\n",
    "<li><p> true negatives (TN): number of objects $\\textbf{not}$ belonging to the class that were $\\textbf{correctly}$ predicted as $\\textbf{not}$ belonging to it; </p>\n",
    "<li><p> false positives (FP): number of objects $\\textbf{not}$ belonging to the class that were $\\textbf{incorrectly}$ predicted as belonging to it; </p>\n",
    "<li><p> false negatives (FN): number of objects belonging to the class that were $\\textbf{incorrectly}$ predicted as $\\textbf{not}$ belonging to it; </p>\n",
    "</ol>\n",
    "\n",
    "Given these four quantities we can define:\n",
    "<ol>\n",
    "<li><p>Precision, or positive predictive value, is the proportion of true positive predictions among all the positive predictions made by the model. In formulas $\\text{precision} = \\frac{\\text{TP}}{\\text{TP} + \\text{FP}}$</p>\n",
    "\n",
    "<li><p>Recall, also termed sensitivity or probability of detection, is the proportion of true positive predictions among all the actual positive cases in the dataset. In formulas $\\text{recall} = \\frac{\\text{TP}}{\\text{TP} + \\text{FN}}$.</p>\n",
    "</ol>\n",
    "\n",
    "\n",
    "A high precision indicates that the model is making few false positive predictions, i.e., positive predictions are correct. A high recall indicates that the model is making few false negative predictions, i.e., the model is correctly identifying all positive cases in the dataset. Ideally we would like both of these measures to be equal to 1, meaning that all objects predicted as belonging to the class are actually from that class (precision=1) and all objects belonging to the class are correctly predicted as belonging to it (recall=1). In general, there is a trade-off between precision and recall: increasing one metric often comes at the expense of the other.  \n",
    "\n",
    "Let's compute precision and recall of our multiclass knn classifier using the confusion matrix we computed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in range(3):\n",
    "    print(f'Performance of multiclass classifier for digit {label} VS all others:')\n",
    "    # to access predictions relative to a given class i we select the i-th column of the confusion matrix\n",
    "    column_counts = cf_matrix[:, label]\n",
    "    # the i-th row corresponds to the images actually belonging to class i \n",
    "    row_counts = cf_matrix[label]\n",
    "\n",
    "    TP = column_counts[label]\n",
    "    FP = sum(column_counts) - column_counts[label]\n",
    "    FN = sum(row_counts) - row_counts[label]\n",
    "    \n",
    "    precision = TP/(TP+FP)\n",
    "    recall = TP/(TP+FN)\n",
    "\n",
    "    print(f'\\t-True positives: {TP}')\n",
    "    print(f'\\t-False positives: {FP}')\n",
    "    print(f'\\t-False negatives: {FN}')\n",
    "    print(f'\\t-Precision: {precision:.2f}')\n",
    "    print(f'\\t-Recall: {recall:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "451f631e87007dfc17411ef878bdb33a",
     "grade": false,
     "grade_id": "cell-9706dc8a04420cff",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We have seen how to compute precision and recall with respect to each digit using the confusion matrix produced in our multiclass setting. We are now going to switch to binary classification and metrics to introduce a useful tool, the receiver operating characteristic curve, or ROC curve. The ROC curve is a graphical representation of the performance of a binary classifier system as its discrimination threshold is varied. It plots the true positive rate (TPR), which is another name for the recall, against the false positive rate (FPR) at various classification thresholds.\n",
    "\n",
    "We need now to define a new measure. The FPR, also termed fall-out or false alarm ratio, measures the proportion of negative cases that are incorrectly classified as positive, in formulas $\\text{recall} = \\frac{\\text{FP}}{\\text{FP} + \\text{TN}}$.\n",
    "\n",
    "Let's implement a function that given a knn model, the label of interest and a classification threshold, computes all the performance measures we discussed until now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5cc914cce20987efeebbaa6332f22e66",
     "grade": false,
     "grade_id": "binary_metrics",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Kontrolle:\n",
    "def compute_binary_metrics(knn, label: int, ground_truth: np.ndarray, threshold: float = .3):\n",
    "    metrics = {}\n",
    "    preds, probs = knn(label, threshold)\n",
    "    target = (ground_truth==label).astype(int)\n",
    "    metrics['TP'] = np.sum((preds==1)&(target==1))               # true_positives\n",
    "    metrics['FP'] = np.sum((preds==1)&(target==0))               # false_positives\n",
    "    metrics['TN'] = np.sum((preds==0)&(target==0))               # true_negative\n",
    "    metrics['FN'] = np.sum((preds==0)&(target==1))               # false_negatives\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()\n",
    "    metrics['precision'] = metrics['TP']/(metrics['TP']+metrics['FP']) if metrics['TP']>0 else 0\n",
    "    metrics['recall'] = metrics['TP']/(metrics['TP']+metrics['FN']) if metrics['TP']>0 else 0\n",
    "    metrics['fall-out'] = metrics['FP']/(metrics['FP']+metrics['TN']) # Fall-Out\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "086a27926fe02c98c1227991a8a20ffa",
     "grade": false,
     "grade_id": "cell-ef9be3f98df88400",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's test our funciton and compare the metrics with the previously computed ones. \n",
    "\n",
    "What is different now, with respect to the multiclass setting, is that we can set the classification threshold. Check how changing the threshold changes the values of our metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.set_k(5)\n",
    "for label in range(3):\n",
    "    print(f'Performance of binary classifier for digit {label}:')\n",
    "    metrics = compute_binary_metrics(knn, label, y_unknown, threshold=.3)\n",
    "    for k, v in metrics.items():\n",
    "        print(f'\\t-{k}: {v:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can use these binary metrics to compute overall multi-class metrics using the following aggregation methods:<ol>\n",
    "<li><p>Micro-averaging: In micro-averaging, we aggregate the binary metrics over all the classes. This means that we sum up the number of true positives, false positives, false negatives, and true negatives over all the classes and then compute the performance metrics.</p>\n",
    "<li><p>Macro-averaging: In macro-averaging, we compute the binary metrics, e.g. precision, for each class separately and then take the average across all the classes. Macro-averaging gives equal weight to all classes and is suitable when we want to evaluate the performance of each class separately.</p>\n",
    "<li><p>Weighted averaging: In weighted averaging, we compute the binary metrics for each class separately and then take the weighted average across all the classes. The weight of each class is proportional to the number of samples from that class in the dataset. Weighted averaging is most suitable averaging technique when the dataset is unbalanced among the various classes.</p>\n",
    "</ol>\n",
    "\n",
    "\n",
    "Below we implemented a function to compute multi-class performance measures aggregating the corresponding binary metrics with weighted averaging. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e19e1aa94b31762ba50c300b1066f333",
     "grade": false,
     "grade_id": "cell-d95e6fcea9692d4d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def compute_multiclass_metrics(knn, ground_truth, threshold=.3, labels=np.arange(10)):\n",
    "    metrics_list = []\n",
    "    for label in labels:\n",
    "        metrics_list.append(compute_binary_metrics(knn, label, ground_truth, threshold))\n",
    "        weights = np.asarray([(ground_truth==label).sum() for label in labels])\n",
    "    multiclass_metrics = {}\n",
    "    for m in ['precision', 'recall', 'fall-out']:\n",
    "        multiclass_metrics[m] = sum([weights[i]*metrics_list[i][m] for i in range(len(labels))])/weights.sum()\n",
    "    return multiclass_metrics, metrics_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.set_k(5)\n",
    "metrics, _ = compute_multiclass_metrics(knn, y_unknown, threshold=.3)\n",
    "print(f'Multiclass knn performance, weighted average: ')\n",
    "for k, v in metrics.items():\n",
    "    print(f'\\t-{k}: {v:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As stated above, the ROC curve is generated by calculating the TPR and FPR for different threshold values, ranging from 0 to 1. As the threshold increases, the model becomes more conservative, classifying fewer instances as positive, which leads to a decrease in the FPR and TPR. Conversely, as the threshold decreases, the model becomes more aggressive, classifying more instances as positive, which leads to an increase in the FPR and TPR.\n",
    "\n",
    "A perfect classifier would have a ROC curve that passes through the top-left corner of the plot (TPR=1, FPR=0), indicating a TPR of 100% and an FPR of 0%. The area under the ROC curve (AUC) is a measure of the overall performance of the classifier, with a value of 1 indicating a perfect classifier and a value of 0.5 indicating a classifier that is no better than random guessing.\n",
    "\n",
    "The following code plots the Recall VS Precision (RvP) curve and the ROC curve (with AUC), so that we can see how modifying the threshold gives us classifiers with different trade-offs for the metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "03e3f6d3713e1ec9a7b7ecff034d6ab1",
     "grade": false,
     "grade_id": "cell-20702f8b17c1bd95",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def plot_measures(knn, y_unknown, plot_type='ROC', all=True):\n",
    "    measures = {'ROC':('fall-out', 'recall'), 'RvP': ('recall', 'precision')}\n",
    "    measures = measures[plot_type]\n",
    "    m0 = {k:[] for k in ['mc']+list(range(10))}\n",
    "    m1 = {k:[] for k in ['mc']+list(range(10))}\n",
    "    for threshold in np.arange(0,1,.1):\n",
    "        mc, bin = compute_multiclass_metrics(\n",
    "                        knn, \n",
    "                        y_unknown, \n",
    "                        threshold)\n",
    "        m0['mc'].append(mc[measures[0]])\n",
    "        m1['mc'].append(mc[measures[1]])\n",
    "        for i in range(10):\n",
    "            m0[i].append(bin[i][measures[0]])\n",
    "            m1[i].append(bin[i][measures[1]])\n",
    "    if all:\n",
    "        for i in range(10):\n",
    "            plt.plot(m0[i][::-1], m1[i][::-1], label='digit_'+str(i))\n",
    "    plt.plot(m0['mc'][::-1], m1['mc'][::-1], label='multiclass')\n",
    "    auc = ''\n",
    "    if plot_type=='ROC':\n",
    "        plt.plot([0, 1], [0, 1], linestyle='dashed', color='red', label='random_guess')\n",
    "        auc = np.abs(np.trapz(y=m1['mc'][::-1], x=m0['mc'][::-1]))\n",
    "        auc = f', AUC: {auc:.3f}'\n",
    "    plt.xlim(0, 1)\n",
    "    plt.ylim(0, 1)\n",
    "    plt.xlabel(measures[0])\n",
    "    plt.ylabel(measures[1])\n",
    "    plt.title(plot_type+auc)\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8c7d14c3da4a8ef2a65620bd6c08a34d",
     "grade": false,
     "grade_id": "cell-ba8f5378c673ceef",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's plot some of the curves varying the number of neighbors we use for the classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in [2, 5, 20]:\n",
    "    print(f'K: {k}')\n",
    "    knn.set_k(k)\n",
    "    plot_measures(knn, y_unknown, all=False, plot_type='RvP')\n",
    "    plot_measures(knn, y_unknown, all=False, plot_type='ROC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2026749f1caa1790c4f6e7a2adfa1a5f",
     "grade": true,
     "grade_id": "knn_classifier_test",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test for grading\n",
    "knn = Knn_Classifier(X_unknown, X_labeled, y_labeled)\n",
    "res = np.asarray([3, 8, 3, 3, 8, 9, 5, 5, 2, 9, 6, 7, 2, 2, 7, 8, 0, 1, 2, 0, 5, 6, 8, 1, 1, 6, 0, 7, 7, 4, 4, 4, 4, 4, 4])\n",
    "assert np.all(knn.nn_targets[2]==res), 'visible test: something wrong in nn_targets'\n",
    "\n",
    "knn.set_k(5)\n",
    "assert knn.knn_targets.shape[-1]==5, 'visible test: something wrong in knn_targets shape'\n",
    "\n",
    "#similar test as above, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1d607a5b18e999c142cccaa09e55762c",
     "grade": true,
     "grade_id": "binary_metrics_test",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test for grading\n",
    "knn = Knn_Classifier(X_unknown, X_labeled, y_labeled)\n",
    "knn.set_k(5)\n",
    "metrics = compute_binary_metrics(knn, label=5, ground_truth=y_unknown, threshold=.3)\n",
    "res = {'TP': 141, 'FP': 38, 'TN': 1545, 'FN': 38, 'precision': 0.7877094972067039, 'recall': 0.7877094972067039, 'fall-out': 0.024005053695514846}\n",
    "for k in metrics.keys():\n",
    "    assert metrics[k]==res[k], f'visible test: metric {k} is wrong'\n",
    "\n",
    "#similar test as above, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ae41c0f0fad9dee6e57ff29c00b1fdc4",
     "grade": false,
     "grade_id": "cell-69e2c302f41a7a78",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 3.3 Dimensionality reduction with PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7be164b88d02b756ee692ac8a7df2ea9",
     "grade": false,
     "grade_id": "cell-e295194e814491ac",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now we will try to reduce the number of features or pixels to two and re-test the precision/recall curves from exercise 3.2.\n",
    "\n",
    "We will try with an unsupervised method, namely via Principle Component Analysis (PCA). The task is to use `scikit-learn`'s implementation of the PCA to reduce the number of pixels to two and then to make a scatter plot of the new features, where the color of each point represents the digits number.  Which property should this scatterplot have in order for the new features to be especially suitable for similarity search?\n",
    "\n",
    "Implement a pca model using the imported sklearn function and transform the image features retaining only 2 components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "78fa8affbb72cf36befd28cb9b0bf2a5",
     "grade": false,
     "grade_id": "PCA",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Kontrolle\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# YOUR CODE HERE\n",
    "pca = PCA(n_components=2)\n",
    "new_features_pca = pca.fit_transform(X_unknown,y_unknown)\n",
    "#raise NotImplementedError()\n",
    "plt.figure(figsize=(9, 7))\n",
    "for i in range(10):\n",
    "    plt.scatter(new_features_pca [y_unknown==i, 0], new_features_pca [y_unknown==i, 1], label=str(i))\n",
    "plt.xlabel('Dim 1')\n",
    "plt.ylabel('Dim 2')\n",
    "plt.title('2D Feature Space')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a691340da6e96cbc60d55febc989c6f3",
     "grade": true,
     "grade_id": "PCA_testsssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssss",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test for grading\n",
    "#checking if correct number of components is retained in new_features_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c82b6a4ef44b3c03a7386a2cee3d3e3c",
     "grade": false,
     "grade_id": "cell-41170211ff7fdd39",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We fixed the number of components to be retained by the PCA to 2, so that we could easily visualize them with the scatter plot. What would be more sensible is to select a number of components sufficient enough to represent the variance of the data, in such a way to keep almost all valuable information carried by our features, but hopefully smaller than the total number of features, so to avoid redundancy. \n",
    "\n",
    "That's what we are doing next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "pca.fit(X_labeled)\n",
    "explained_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "n_dim = next(ind for ind, x in enumerate(explained_variance) if x > .9)\n",
    "print(f'Original number of features: {X_labeled.shape[-1]}')\n",
    "print(f'Using only {n_dim} dimensions is enough to explain the 90% of the variance in the data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot now the ROC curves of the knn classifier trained using all features and of the knn classifier with PCA reduced features. The performance improves only slightly in this specific example, but PCA reduction is a useful method o avoid overfitting in settings where the dimension of the dataset is small with respect to the dimension of the feature spacet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ROC curve of knn classifier using all available features')\n",
    "knn = Knn_Classifier(X_unknown, X_labeled, y_labeled)\n",
    "knn.set_k(5)\n",
    "plot_measures(knn, y_unknown, all=False, plot_type='ROC')\n",
    "\n",
    "print(f'ROC curve of knn classifier using {n_dim} most \"important\" features')\n",
    "pca = PCA(n_components=n_dim)\n",
    "pca.fit(X_labeled)\n",
    "knn = Knn_Classifier(pca.transform(X_unknown), pca.transform(X_labeled), y_labeled)\n",
    "knn.set_k(5)\n",
    "plot_measures(knn, y_unknown, all=False, plot_type='ROC')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
